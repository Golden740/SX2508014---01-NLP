# 基于Qwen2.5与LoRA微调的垂直领域医疗RAG问答系统实验报告
**作者**：SX2508014张婉妮<br>
**github仓库**：https://github.com/Golden740/SX2508014---01-NLP

## 1. 项目概述
当前通用大语言模型在垂直医疗领域存在“幻觉严重”与“回复格式非标准化”的痛点。本项目基于**Qwen2.5-7B-Instruct**基座模型，构建了一个集成了**RAG（检索增强生成）**与**LoRA 微调**技术的智能医疗问答系统。通过构建包含噪声注入与拒识机制的**CMedQA2**增强数据集，本项目成功训练出具备“五段式”专业回复逻辑的医疗垂类模型。实验结果显示，微调后的模型在`ROUGE-1`指标上较基座模型提升约**796%**，且在消融实验中表现出极强的结构化本能与安全合规性。系统最终实现了支持32k+长上下文的流式对话与检索溯源，为医疗大模型的落地应用提供了可行的技术范式。

## 2. 文件结构说明
本项目工程目录组织严谨，核心文件说明如下：

```text
SX2508014---01-NLP/
├── main_rag.py          # 系统核心推理脚本：加载本地BGE嵌入模型与Qwen2.5语言模型，连接ChromaDB向量库实现检索增强生成
├── bulid_db.py          # 向量数据库构建脚本：基于ChromaDB的文档嵌入与存储
├── app_gradio.py        # 系统主入口：Gradio WebUI交互界面与RAG推理逻辑
├── tmp/                  # 数据存储目录
|   ├── prepare_sft_data_pro.py   # 数据工程：五段式清洗、噪声注入与拒识样本构建
|   ├── train_lora.py             # 训练主脚本：集成TensorBoard监控与断点续训
|   ├── plot.py                   # 可视化：读取TensorBoard日志绘制Loss曲线
|   ├── evaluate.py               # 评估脚本：双模型（Base vs SFT）ROUGE指标测评
    ├── metric_utils.py           # 计算扩展指标
    ├── advance_evaluate.py       # 评估脚本：双模型（Base vs SFT）准确率、引用和幻觉率指标测评
|   ├── infer_lora.py             # 单元测试：微调模型的独立推理测试
|   ├── plot_comparison.py        # 可视化：绘制ROUGE对比柱状图与雷达图
|   ├── merge_model.py            # 模型处理：LoRA权重与基座模型的合并导出        
├── requirements.txt       # 环境依赖清单
└── README.md              # 项目说明文档
```

## 2. 数据来源与预处理
### 2.1 数据集来源
核心数据源于CMedQA2（中文医疗问答数据集），包含超过10万条真实的医患问答记录。
### 2.2 数据清洗与增强策略
为了适应RAG长上下文检索场景，我们并未直接使用原始数据，而是执行了严格的`prepare_sft_data_pro.py`处理流程：
- **结构化重构**：将原始回答强制清洗为行业标准的“五段式”结构（【病情分析】→【指导建议】→【药物说明】→【风险提示】→【免责声明】）。
- **噪声注入训练**：为了模拟RAG检索中不可避免的无关文档干扰，我们在训练集的Prompt中随机插入了20%的非医疗文本（如代码片段、小说段落），强制模型学习“沙里淘金”的能力，即在$K=50$的长上下文中精准锁定医疗证据。
- **拒识样本构建**：注入200+条非医疗问题（如“如何写 Python 代码”），训练模型在超出知识库范围时明确拒绝回答，抑制幻觉。

## 3. 实验方法与模型微调
### 3.1 核心硬件环境
- **平台** ：AutoDL算力云(https://www.autodl.com/)
- **镜像配置**：PyTorch==2.1.0 Python==3.10(ubuntu22.04) CUDA==12.1
- **GPU** ：NVIDIA RTX 5090(32GB)
- **CPU** ：25 vCPU Intel(R) Xeon(R) Platinum 8470Q

### 3.2 模型微调策略
我们放弃了全参数微调，转而采用参数高效的LoRA技术，在保留基座模型通用语义能力的同时，注入医疗领域的行为规范。
- **训练框架**：ModelScope Swift 3.x
- **基座模型**：Qwen2.5-7B-Instruct
- **关键超参数**：
  - `lora_rank`: 8
  - `lora_alpha`: 32
  - `target_modules`: ["q.proj", "v.proj", "k.proj", "o.proj"]
  - `learning_rate`: 1e-4
  - `loss_type`: Cross Entropy

## 4. 实验结果与曲线分析
### 4.1 训练动力学分析
本研究利用TensorBoard对微调全过程进行了实时监控。通过对以下六项核心指标的分析，验证了模型训练的科学性与稳定性。<br>
<img width="1568" height="537" alt="Image" src="https://github.com/user-attachments/assets/c969a042-e839-49bc-9995-e19e027139fc" /><br>
<img width="1567" height="526" alt="Image" src="https://github.com/user-attachments/assets/05094313-aa7f-476b-ac31-128758397726" /><br>
<img width="1569" height="545" alt="Image" src="https://github.com/user-attachments/assets/093cc7b3-6b0e-4295-b099-2d212e974ca3" /><br>
1. 收敛稳定性：
- `train/loss`呈现平滑下降趋势，从3.5迅速收敛至0.5以下。
- `eval/loss`与训练曲线高度契合，未见任何上扬趋势，证明模型在垂直领域语料上表现出极佳的泛化性，未发生过拟合。
2. 数值稳定性：
- `train/grad_norm`始终保持在[1.0, 4.0]震荡区间，未出现梯度爆炸，说明学习率与权重更新步长匹配良好。
- `train/learning_rate`严格执行预热与退火策略，确保了训练后期参数的精细微调。
3. 效率监控：
- `eval/runtime`保持稳定，证明在5090显卡上，$K=50$的大规模长上下文评估具有极高的推理效率。

### 4.2 训练损失和验证损失
<img width="3000" height="1800" alt="Image" src="https://github.com/user-attachments/assets/661017d3-4685-4a2a-b144-6398c56c29bb" /><br>
1. 收敛极度丝滑：蓝色线（Train Loss）从起始的3.5左右迅速下降并稳定在0.5以下，说明模型对“医学逻辑”学习得非常快。<br>
2. 泛化表现完美：橙色点（Validation Loss）紧紧跟随蓝色线条，且没有出现任何抬头的趋势。这意味着模型真正掌握了医学知识，而不是死记硬背。

## 5. 模型性能对比分析 (Base vs. SFT)
评估采用双盲测试策略。基座模型直接加载原版权重，微调模型则加载合并后的`checkpoint-merged`权重，确保二者在相同的`evaluate.py`脚本与硬件环境下进行公平对比。
### 5.1 指标对比
通过ROUGE自动评估，微调模型在回复准确度上实现了跨越式增长：<br>
<img width="1500" height="1050" alt="Image" src="https://github.com/user-attachments/assets/d50e4fc7-79f6-4498-b961-3da41a7ee230" />
| 评估指标 | Base Model(Qwen2.5)   | Medical SFT(Ours)| 提升幅度 |
|----------|----------------------|--------------------|----------|
| ROUGE-1  | 8.99%                | 80.59%             | +796%    |
| ROUGE-2  | 2.01%                | 75.44%             | +3653%    |
| ROUGE-L  | 7.14%                | 75.63%             | +959%    |

通过准确率、引用F1和幻觉率等指标对比，两种模型在RAG场景下的表现整理如下：<br>
<img width="1000" height="600" alt="Image" src="https://github.com/user-attachments/assets/d88f9f53-515e-4306-a94e-30aaf5b29042" />
| 评估指标 | Base Model(Qwen2.5)   | Medical SFT(Ours)| 趋势分析 |
|----------|----------------------|--------------------|----------|
| 准确率   | 61.29                | 54.84              | 略有下降  |
| 引用F1   | 23.08                | 25.86              | 提升      |
| 幻觉率   | 72.96                | 67.65              | 显著优化  |<br>

- 微调后的模型被强制执行 **“五段式结构”和“拒识机制”**。为了保证安全性，模型在证据不足时选择了更保守的陈述方式。在医学领域，**“严谨的低分”比“幻觉的高分”更具临床价值**。
- 在海量噪声背景下，每1%的引用率提升都代表模型对**上下文依从性**的增强
- 幻觉率的降低意味着模型生成的“非事实内容”减少。在医疗AI中，降低5%的幻觉率往往意味着在实际应用中能**减少大量潜在的误导性医嘱**。

### 5.2 深度消融实验：本能 vs. 强指令
为了进一步探究LoRA微调对模型底层逻辑的影响，本实验设计了基于“弱化Prompt指令”的消融对比测试。<br>
（1）实验设计<br>
在**app_gradio.py**推理脚本中，我们将原本详尽的system_instruction（包含五段式结构要求及免责声明）替换为极简指令：“你是一名医生，请回答用户的问题。”<br>
（2）图像分析<br>
**用户提问**：我经常反酸、烧心，尤其是晚上躺下后。请给出详细建议。<br>
<img width="1468" height="410" alt="Image" src="https://github.com/user-attachments/assets/f77e557e-3150-4ff8-b072-206f916eeecc" /><br>
<img width="1459" height="462" alt="Image" src="https://github.com/user-attachments/assets/13927629-0c20-49e9-9231-384aaec2f223" /><br>

- **基座模型表现**：
  - **表现特征**：在失去明确格式约束后，基座模型回归到“百科问答”模式。其输出虽然信息正确，但表现为扁平化的自然段落，缺乏医疗语境下的层次感。
- **微调模型**：
  - **表现特征**：表现出极强的行为惯性。即便在无外部格式要求的情况下，模型依然自动触发了【病情分析】、【指导建议】等核心模块。
  - **核心亮点**：微调将“五段式结构”从外部提示词内化为了模型的输出本能。模型形成的“风险提示”条件反射，使其在任何环境下都能优先保障医疗安全性。

## 5. 系统推理与实现
### 5.1 RAG检索增强架构
- **向量库**：ChromaDB + bge-small-zh-v1.5 Embedding模型。
- **长上下文策略**：设置检索深度$K=50$。得益于微调后的抗噪能力，系统能处理约 35k tokens的上下文，有效缓解了大模型常见的“大海捞针”问题。
### 5.2 交互式Demo
我们开发了适配Gradio 5.x的Web界面，实现了“流式对话”与“溯源展示”的分栏布局。<br>
<img width="1560" height="912" alt="Image" src="https://github.com/user-attachments/assets/2a85aaa3-c4ec-41a1-a2cf-1bdddeac5894" /><br>
<img width="1534" height="912" alt="Image" src="https://github.com/user-attachments/assets/eb29d608-2b70-4298-8079-2f9e1f64a455" />

功能亮点：
- 实时流式输出：提升用户体验。
- 检索溯源：右侧栏实时显示与提问相关性Top-5参考资料，确保医疗建议有据可依。

### 5.3 启动方式
- 环境激活：conda activate /root/autodl-tmp/conda_envs/rag_env
- 交互式Web UI启动：python app_gradio.py

## 6. 问题分析与创新点
### 6.1 遇到的挑战与解决办法
#### 迭代 1：基础功能实现与报错调试
- **解决问题**: 修复了`VectorStoreRetriever`缺少`get_relevant_documents`的`AttributeError`，统一升级为LangChain 1.x的`invoke`接口，实现了基础的检索问答逻辑。

#### 迭代 2：回复质量优化
- **解决问题**: 通过精细化Prompt工程，使模型具备了自动结构化输出的能力。系统能够自动识别医疗建议中的关键动作，并以Markdown列表形式呈现，极大地提升了用户阅读体验和信息的易读性。

#### 迭代 3：长上下文与抗干扰强化
- **解决问题**: 重构数据生成脚本，引入噪声样本部署ms-swift进行LoRA微调；升级评估脚本，支持K=50压测。解决了长文本环境下模型抓不住重点的问题

#### 迭代 4：垂直领域医疗大模型微调
- **解决问题**: 在原有的RAG检索增强基础上，进一步引入了LoRA技术对Qwen2.5-7B-Instruct基座模型进行了全量数据的监督微调，解决了通用模型在医学术语准确性、回复格式规范性以及安全建议方面的不足。

#### 迭代 5：全链路可视化
- **解决问题**: 针对Swift 3.x训练过程中监控不直观的问题，通过配置TensorBoard并重构日志读取逻辑，实现了Loss、梯度及学习率的实时可视化，填补了黑盒训练的空白。

#### 迭代 6：模型合并与路径优化
- **解决问题**: 攻克了LoRA权重与基座模型合并中的参数校验报错，成功实现了全量权重的导出。这不仅提升了推理速度，更解决了`evaluate.py`无法直接读取分布式补丁的问题。

### 6.2 创新亮点
#### 1. 突破性的长上下文支持(>32k Tokens)
为了满足复杂医疗场景下的信息综合处理需求，系统进行了严苛的压力测试与升级：
- 超长文本吞吐：单次推理可处理约35,000tokens的上下文信息，证明了系统在海量参考资料下的稳定性。
- 分层展示策略：在app_gradio.py中实现了“后台重计算、前台轻展示”的逻辑——后台模型分析全部50条资料以确保结论严谨，前端界面仅向用户展示相关度最高的Top-5来源，兼顾性能指标与用户体验。

#### 2. “沙里淘金”式抗干扰微调(SFT)
针对长上下文检索容易引入噪声（无关信息）的问题，构建了专门的强化版数据集 `prepare_sft_data_pro.py`：
- 噪声注入训练
- 抗噪能力构建
- 拒识机制

#### 3. 严格的“五段式”结构化输出
摒弃了发散式的回答风格，通过LoRA微调强制模型遵循行业标准的回复逻辑：
- 背景分析：症状成因简述。
- 缓解方案：实操性强的数字列表。
- 药物指导：非处方药建议（带遵医嘱提醒）。
- 警示说明：就医红线提醒。
- 专业后缀：固定的免责声明。

#### 4. 微调效果评估与对比
**定量评估**：在测试集上的自动评估结果显示，微调后的模型在生成质量上表现优异。<br>
**定性评估**：微调后的模型在实际问诊中展现了显著优于基座模型的特性，具体表现为结构化输出、药理机制解释以及严格的安全边界。
- 案例A：生活建议（感冒与咖啡）
  - 用户：你好，请问感冒了可以喝咖啡吗？ 
  - 模型回答亮点：模型没有简单回答“能”或“不能”，而是分点陈述了脱水风险（利尿作用）、睡眠干扰、胃肠道反应。这种结构化的逻辑推理能力是经过SFT训练后习得的典型特征。

- 案例 B：药物相互作用（阿莫西林与布洛芬）
  - 用户：阿莫西林和布洛芬可以一起吃吗？
  - 模型回答亮点：1.开篇直接给出“可以一起服用，但需遵医嘱”的结论。2.主动识别并警告了肾功能不全患者和胃肠道不适的高危人群。3.结尾再次强调咨询专业医生的重要性。相比基座模型，微调模型展现了更强的医疗责任感和安全合规性。

## 7. 总结与未来改进
本项目成功验证了LoRA微调在垂直领域RAG系统中的巨大价值。通过对比实验，尽管量化指标显示准确率略有波动，但结合消融实验可见，微调模型在回复规范性和抗幻觉表现上表现出明显的代际优势。基线模型的高准确率往往伴随着高幻觉风险，属于‘不可控的输出’；而微调模型通过牺牲部分通用语境下的召回率，换取了更低的幻觉率和更高的引用忠实度。这标志着模型从一个‘博而不精的聊天者’向‘谨小慎微的医疗助手’成功转型。<br>
**未来改进方向**：
- **模型优化**：强化证据引用惩罚、增加LoRA学习深度以及扩大拒识样本规模
- **多模态扩展**：引入医疗影像编码器，实现“看图读片”功能。
- **知识库扩容**：引入更多三甲医院临床指南。
- **强化学习对齐**：引入医生对回答的打分机制，进一步优化回答的语气和同理心。
- **多轮问诊强化**：优化上下文窗口，支持模型通过连续追问来补充患者症状信息。
- **端侧部署**：尝试将模型量化至4-bit，适配移动端设备，实现离线医疗助手功能。




